{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p align=center>Web Scraping de los viajes en taxi en Manhattan, NY</p>\n",
    "### <p align=center>Período: 2016-2019</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from google.cloud import storage\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL del sitio web\n",
    "\n",
    "url = 'https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia de la clase requests\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# Creación de un objeto BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Lista vacía para almacenar los enlaces\n",
    "\n",
    "links = []\n",
    "\n",
    "# Búsqueda de la clase 'faq-answers' en el objeto soup\n",
    "\n",
    "faq_answers = soup.find_all('div', class_='faq-answers')\n",
    "\n",
    "# Bucle for para obtener los enlaces con parámetros específicos (extensión .parquet, años 2016 a 2019, yellow taxis)\n",
    "\n",
    "for div in faq_answers:\n",
    "    for a in div.find_all('a', href=True):\n",
    "        href = a['href']\n",
    "        if href.endswith('.parquet') and 'yellow' in href and re.search(r'201[6-9]', href):\n",
    "            \n",
    "            # Agregar los enlaces a la lista\n",
    "\n",
    "            links.append(href)\n",
    "\n",
    "df = pd.DataFrame(links, columns=['links'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://d37ci6vzurychx.cloudfront.net/trip-dat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               links\n",
       "0  https://d37ci6vzurychx.cloudfront.net/trip-dat..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo yellow_tripdata_2019-01.parquet subido a Cloud Storage\n"
     ]
    }
   ],
   "source": [
    "# Configuración de la autenticación de GCP\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'datalogic-taxis-ny-4d9c91e757e1.json'\n",
    "\n",
    "# Creación de un cliente de GCP\n",
    "\n",
    "client = storage.Client()\n",
    "bucket_name = 'prueba_datalogic'\n",
    "bucket = client.bucket(bucket_name)\n",
    "\n",
    "for url in df['links']:\n",
    "    file_name = url.split('/')[-1]\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "\n",
    "        # Guardamos el archivo localmente\n",
    "        with open(file_name, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        # Leemos el archivo con pandas y seleccionamos las columnas que nos interesan\n",
    "        df = pd.read_parquet(file_name)\n",
    "        df = df[['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'PULocationID', 'DOLocationID', 'payment_type', 'total_amount']]\n",
    "\n",
    "        # Renombramos las columnas traduciendo los nombres\n",
    "        df.rename(columns={'tpep_pickup_datetime': 'fecha_hora_subida', 'tpep_dropoff_datetime': 'fecha_hora_bajada', 'passenger_count': 'cantidad_pasajeros', 'trip_distance': 'distancia_recorrida', 'PULocationID': 'zona_subida', 'DOLocationID': 'zona_bajada', 'payment_type': 'tipo_pago', 'total_amount': 'monto_total'}, inplace=True)\n",
    "\n",
    "        # Guardamos el archivo con los datos limpios\n",
    "        df.to_parquet(file_name, index=False)\n",
    "        \n",
    "        # Lo subimos a Cloud Storage\n",
    "        blob = bucket.blob(file_name)\n",
    "        blob.upload_from_filename(file_name)\n",
    "\n",
    "        # Eliminamos el archivo local\n",
    "        os.remove(file_name)\n",
    "\n",
    "        print(f'Archivo {file_name} subido a Cloud Storage')\n",
    "\n",
    "        # Como estamos haciendo una prueba, detenemos el bucle después de subir un archivo\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        print(f'Error en la descarga del archivo {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in df['links']:\n",
    "    file_name = url.split('/')[-1]\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "\n",
    "        # Guardamos el archivo localmente\n",
    "        with open(file_name, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        # Leemos el archivo con pandas y seleccionamos las columnas que nos interesan\n",
    "        df = pd.read_parquet(file_name)\n",
    "        df = df[['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'PULocationID', 'DOLocationID', 'payment_type', 'total_amount']]\n",
    "\n",
    "        # Renombramos las columnas traduciendo los nombres\n",
    "        df.rename(columns={'tpep_pickup_datetime': 'fecha_hora_subida', 'tpep_dropoff_datetime': 'fecha_hora_bajada', 'passenger_count': 'cantidad_pasajeros', 'trip_distance': 'distancia_recorrida', 'PULocationID': 'zona_subida', 'DOLocationID': 'zona_bajada', 'payment_type': 'tipo_pago', 'total_amount': 'monto_total'}, inplace=True)\n",
    "\n",
    "        # Guardamos el archivo con los datos limpios\n",
    "        df.to_parquet(file_name, index=False)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_hora_subida</th>\n",
       "      <th>fecha_hora_bajada</th>\n",
       "      <th>cantidad_pasajeros</th>\n",
       "      <th>distancia_recorrida</th>\n",
       "      <th>zona_subida</th>\n",
       "      <th>zona_bajada</th>\n",
       "      <th>tipo_pago</th>\n",
       "      <th>monto_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:46:40</td>\n",
       "      <td>2019-01-01 00:53:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>151</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fecha_hora_subida   fecha_hora_bajada  cantidad_pasajeros  \\\n",
       "0 2019-01-01 00:46:40 2019-01-01 00:53:20                 1.0   \n",
       "\n",
       "   distancia_recorrida  zona_subida  zona_bajada  tipo_pago  monto_total  \n",
       "0                  1.5          151          239          1         9.95  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
